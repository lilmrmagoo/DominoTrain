{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1316acf-caa2-4874-9b14-171dae29e3dd",
   "metadata": {},
   "source": [
    "<h1>Install Dependcies</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a1d00a0-5e6e-4662-93bf-0946f386f08e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/74/07/edce54779f5c3fe8ab8390eafad3d7c8190fce68f922a254ea77f4a94a99/torch-2.1.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached torch-2.1.0-cp311-cp311-win_amd64.whl.metadata (25 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/5e/5d/97afbafd9d584ff1b45fcb354a479a3609bd97f912f8f1f6c563cb1fae21/filelock-3.12.4-py3-none-any.whl.metadata\n",
      "  Using cached filelock-3.12.4-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\python311\\lib\\site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in c:\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lilmr\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.1.2)\n",
      "Collecting fsspec (from torch)\n",
      "  Obtaining dependency information for fsspec from https://files.pythonhosted.org/packages/fe/d3/e1aa96437d944fbb9cc95d0316e25583886e9cd9e6adc07baad943524eda/fsspec-2023.9.2-py3-none-any.whl.metadata\n",
      "  Using cached fsspec-2023.9.2-py3-none-any.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lilmr\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Using cached torch-2.1.0-cp311-cp311-win_amd64.whl (192.3 MB)\n",
      "Using cached filelock-3.12.4-py3-none-any.whl (11 kB)\n",
      "Using cached fsspec-2023.9.2-py3-none-any.whl (173 kB)\n",
      "Installing collected packages: networkx, fsspec, filelock, torch\n",
      "Successfully installed filelock-3.12.4 fsspec-2023.9.2 networkx-3.1 torch-2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts convert-caffe2-to-onnx.exe, convert-onnx-to-caffe2.exe and torchrun.exe are installed in 'C:\\Users\\lilmr\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in c:\\python311\\lib\\site-packages (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\python311\\lib\\site-packages (from gymnasium) (1.26.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\python311\\lib\\site-packages (from gymnasium) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\python311\\lib\\site-packages (from gymnasium) (4.8.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\python311\\lib\\site-packages (from gymnasium) (0.0.4)\n",
      "Collecting stable-baselines3[extra]\n",
      "  Obtaining dependency information for stable-baselines3[extra] from https://files.pythonhosted.org/packages/5e/81/7a0fbfc45240ec36cc3fcfe8f135996ef03277e2305d941a6d9186eb14e8/stable_baselines3-2.1.0-py3-none-any.whl.metadata\n",
      "  Using cached stable_baselines3-2.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in c:\\python311\\lib\\site-packages (from stable-baselines3[extra]) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\python311\\lib\\site-packages (from stable-baselines3[extra]) (1.26.0)\n",
      "Requirement already satisfied: torch>=1.13 in c:\\users\\lilmr\\appdata\\roaming\\python\\python311\\site-packages (from stable-baselines3[extra]) (2.1.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\python311\\lib\\site-packages (from stable-baselines3[extra]) (2.2.1)\n",
      "Requirement already satisfied: pandas in c:\\python311\\lib\\site-packages (from stable-baselines3[extra]) (2.1.1)\n",
      "Collecting matplotlib (from stable-baselines3[extra])\n",
      "  Obtaining dependency information for matplotlib from https://files.pythonhosted.org/packages/40/d9/c1784db9db0d484c8e5deeafbaac0d6ed66e165c6eb4a74fb43a5fa947d9/matplotlib-3.8.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached matplotlib-3.8.0-cp311-cp311-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting opencv-python (from stable-baselines3[extra])\n",
      "  Obtaining dependency information for opencv-python from https://files.pythonhosted.org/packages/38/d2/3e8c13ffc37ca5ebc6f382b242b44acb43eb489042e1728407ac3904e72f/opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl.metadata\n",
      "  Using cached opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Collecting pygame (from stable-baselines3[extra])\n",
      "  Obtaining dependency information for pygame from https://files.pythonhosted.org/packages/82/61/93ae7afbd931a70510cfdf0a7bb0007540020b8d80bc1d8762ebdc46479b/pygame-2.5.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached pygame-2.5.2-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in c:\\python311\\lib\\site-packages (from stable-baselines3[extra]) (2.14.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\lilmr\\appdata\\roaming\\python\\python311\\site-packages (from stable-baselines3[extra]) (5.9.5)\n",
      "Requirement already satisfied: tqdm in c:\\python311\\lib\\site-packages (from stable-baselines3[extra]) (4.66.1)\n",
      "Collecting rich (from stable-baselines3[extra])\n",
      "  Obtaining dependency information for rich from https://files.pythonhosted.org/packages/be/2a/4e62ff633612f746f88618852a626bbe24226eba5e7ac90e91dcfd6a414e/rich-13.6.0-py3-none-any.whl.metadata\n",
      "  Using cached rich-13.6.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting shimmy[atari]~=1.1.0 (from stable-baselines3[extra])\n",
      "  Obtaining dependency information for shimmy[atari]~=1.1.0 from https://files.pythonhosted.org/packages/d5/fb/083e36bbcf325f6304bbeb2278b102c4ac8e87eb1ca771780f64decbb2f1/Shimmy-1.1.0-py3-none-any.whl.metadata\n",
      "  Using cached Shimmy-1.1.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting pillow (from stable-baselines3[extra])\n",
      "  Obtaining dependency information for pillow from https://files.pythonhosted.org/packages/54/9b/debe992677af84859ec1e38777b1d5c0671918188324153ecbc1f16f6cb6/Pillow-10.0.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached Pillow-10.0.1-cp311-cp311-win_amd64.whl.metadata (9.6 kB)\n",
      "Collecting autorom[accept-rom-license]~=0.6.1 (from stable-baselines3[extra])\n",
      "  Using cached AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
      "Collecting click (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra])\n",
      "  Obtaining dependency information for click from https://files.pythonhosted.org/packages/00/2e/d53fa4befbf2cfa713304affc7ca780ce4fc1fd8710527771b58311a3229/click-8.1.7-py3-none-any.whl.metadata\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\lilmr\\appdata\\roaming\\python\\python311\\site-packages (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.31.0)\n",
      "Collecting AutoROM.accept-rom-license (from autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra])\n",
      "  Using cached AutoROM.accept_rom_license-0.6.1-py3-none-any.whl\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\python311\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.8.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\python311\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (0.0.4)\n",
      "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.1.0->stable-baselines3[extra])\n",
      "  Using cached ale_py-0.8.1-cp311-cp311-win_amd64.whl (952 kB)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\python311\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\python311\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.59.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\python311\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.23.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\python311\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\python311\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.4.4)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\python311\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (4.24.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\python311\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (65.5.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\lilmr\\appdata\\roaming\\python\\python311\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\python311\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\python311\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\lilmr\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.12.4)\n",
      "Requirement already satisfied: sympy in c:\\python311\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\lilmr\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lilmr\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\lilmr\\appdata\\roaming\\python\\python311\\site-packages (from torch>=1.13->stable-baselines3[extra]) (2023.9.2)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->stable-baselines3[extra])\n",
      "  Obtaining dependency information for contourpy>=1.0.1 from https://files.pythonhosted.org/packages/e5/76/94bc17eb868f8c7397f8fdfdeae7661c1b9a35f3a7219da308596e8c252a/contourpy-1.1.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached contourpy-1.1.1-cp311-cp311-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->stable-baselines3[extra])\n",
      "  Obtaining dependency information for cycler>=0.10 from https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl.metadata\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->stable-baselines3[extra])\n",
      "  Obtaining dependency information for fonttools>=4.22.0 from https://files.pythonhosted.org/packages/ae/f6/724d2d236797ea7479a5a7ec8e69c2bee60cad70273cf25078810415ae2d/fonttools-4.43.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached fonttools-4.43.1-cp311-cp311-win_amd64.whl.metadata (155 kB)\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib->stable-baselines3[extra])\n",
      "  Obtaining dependency information for kiwisolver>=1.0.1 from https://files.pythonhosted.org/packages/1e/37/d3c2d4ba2719059a0f12730947bbe1ad5ee8bff89e8c35319dcb2c9ddb4c/kiwisolver-1.4.5-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached kiwisolver-1.4.5-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lilmr\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->stable-baselines3[extra]) (23.2)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->stable-baselines3[extra])\n",
      "  Obtaining dependency information for pyparsing>=2.3.1 from https://files.pythonhosted.org/packages/39/92/8486ede85fcc088f1b3dba4ce92dd29d126fd96b0008ea213167940a2475/pyparsing-3.1.1-py3-none-any.whl.metadata\n",
      "  Using cached pyparsing-3.1.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lilmr\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python311\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2023.3)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->stable-baselines3[extra])\n",
      "  Obtaining dependency information for markdown-it-py>=2.2.0 from https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl.metadata\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lilmr\\appdata\\roaming\\python\\python311\\site-packages (from rich->stable-baselines3[extra]) (2.16.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lilmr\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.6)\n",
      "Collecting importlib-resources (from ale-py~=0.8.1->shimmy[atari]~=1.1.0->stable-baselines3[extra])\n",
      "  Obtaining dependency information for importlib-resources from https://files.pythonhosted.org/packages/65/6e/09d8816b5cb7a4006ef8ad1717a2703ad9f331dae9717d9f22488a2d6469/importlib_resources-6.1.0-py3-none-any.whl.metadata\n",
      "  Using cached importlib_resources-6.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python311\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\python311\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra])\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lilmr\\appdata\\roaming\\python\\python311\\site-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lilmr\\appdata\\roaming\\python\\python311\\site-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lilmr\\appdata\\roaming\\python\\python311\\site-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lilmr\\appdata\\roaming\\python\\python311\\site-packages (from requests->autorom[accept-rom-license]~=0.6.1->stable-baselines3[extra]) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lilmr\\appdata\\roaming\\python\\python311\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\python311\\lib\\site-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\python311\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n",
      "Using cached matplotlib-3.8.0-cp311-cp311-win_amd64.whl (7.6 MB)\n",
      "Using cached Pillow-10.0.1-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "Using cached opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "Using cached pygame-2.5.2-cp311-cp311-win_amd64.whl (10.8 MB)\n",
      "Using cached rich-13.6.0-py3-none-any.whl (239 kB)\n",
      "Using cached stable_baselines3-2.1.0-py3-none-any.whl (178 kB)\n",
      "Using cached contourpy-1.1.1-cp311-cp311-win_amd64.whl (480 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached fonttools-4.43.1-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "Using cached kiwisolver-1.4.5-cp311-cp311-win_amd64.whl (56 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached Shimmy-1.1.0-py3-none-any.whl (37 kB)\n",
      "Using cached importlib_resources-6.1.0-py3-none-any.whl (33 kB)\n",
      "Installing collected packages: pyparsing, pygame, pillow, opencv-python, mdurl, kiwisolver, importlib-resources, fonttools, cycler, contourpy, click, shimmy, matplotlib, markdown-it-py, AutoROM.accept-rom-license, autorom, ale-py, stable-baselines3, rich\n",
      "Successfully installed AutoROM.accept-rom-license-0.6.1 ale-py-0.8.1 autorom-0.6.1 click-8.1.7 contourpy-1.1.1 cycler-0.12.1 fonttools-4.43.1 importlib-resources-6.1.0 kiwisolver-1.4.5 markdown-it-py-3.0.0 matplotlib-3.8.0 mdurl-0.1.2 opencv-python-4.8.1.78 pillow-10.0.1 pygame-2.5.2 pyparsing-3.1.1 rich-13.6.0 shimmy-1.1.0 stable-baselines3-2.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts fonttools.exe, pyftmerge.exe, pyftsubset.exe and ttx.exe are installed in 'C:\\Users\\lilmr\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown-it.exe is installed in 'C:\\Users\\lilmr\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script AutoROM.exe is installed in 'C:\\Users\\lilmr\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script ale-import-roms.exe is installed in 'C:\\Users\\lilmr\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch --user\n",
    "!pip install gymnasium --user\n",
    "!pip install stable-baselines3[extra] --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dd6524-ba81-460c-a988-bee0d8287b1c",
   "metadata": {},
   "source": [
    "<h1>Imports</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "59b2f177-93ed-4639-8145-f3663d267b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gym import Env\n",
    "from gym.spaces import Discrete,MultiDiscrete, Box\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0559ae38-5d01-4ad0-93b4-f644788fc313",
   "metadata": {},
   "source": [
    "<h1>Create Game Classes</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbd84fd4-c327-48c7-b4d3-65aeae0734bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load classes.py\n",
    "import functools\n",
    "import random\n",
    "class Domino():\n",
    "    def __init__(self, s1:int,s2:int):\n",
    "        self.sides = (s1,s2)\n",
    "        self.isDouble = (s1 == s2)\n",
    "    def evalute_side(self, side: int):\n",
    "        if(self.sides[0] == side): return 0\n",
    "        elif (self.sides[1] == side): return 1\n",
    "    def calc_points(self):\n",
    "        return self.sides[0] + self.sides[1]\n",
    "    def __str__(self):\n",
    "        return str(self.sides)\n",
    "\n",
    "\n",
    "class BoneYard():\n",
    "    def __init__(self):\n",
    "        self.dominos = []\n",
    "        self.build()\n",
    "        self.shuffle()\n",
    "    def build(self):\n",
    "        for i in range(0,13):\n",
    "            for j in range(i,13):\n",
    "                self.dominos.append(Domino(i,j))\n",
    "    def shuffle(self):\n",
    "        random.shuffle(self.dominos)\n",
    "    def draw(self):\n",
    "        if len(self.dominos) == 0: return False\n",
    "        return self.dominos.pop()\n",
    "\n",
    "\n",
    "class Train():\n",
    "    startingSide = 12\n",
    "    def __init__(self, id):\n",
    "        self.openSides = [Train.startingSide]\n",
    "        self.trainUp = False\n",
    "        self.id = id\n",
    "    def add(self,placement,domino):\n",
    "        placeIndex = self.openSides.index(placement)\n",
    "        trainSide = self.openSides[placeIndex]\n",
    "        if(trainSide in domino.sides):\n",
    "            if(domino.isDouble):\n",
    "                self.openSides.pop(placeIndex)\n",
    "                self.openSides.append(domino.sides[0])\n",
    "                self.openSides.append(domino.sides[1])\n",
    "            else:\n",
    "                self.openSides.pop(placeIndex)\n",
    "                self.openSides.append(domino.sides[1-domino.evalute_side(trainSide)])\n",
    "        else:\n",
    "            return False\n",
    "    def __str__(self):\n",
    "        return f\"id: {self.id} trainUp?:{self.trainUp} openSides: {self.openSides}\"\n",
    "        \n",
    "\n",
    "class Player():\n",
    "    handSize = 12\n",
    "    nextID = 0 \n",
    "    def __init__(self,boneYard:BoneYard):\n",
    "        self.id = Player.nextID\n",
    "        Player.nextID +=1\n",
    "        self.hand = []\n",
    "        for _ in range(Player.handSize): self.hand.append(boneYard.draw()) \n",
    "    def highestDouble(self):\n",
    "        highest = -1\n",
    "        for domino in self.hand:\n",
    "            if(domino.isDouble and domino.sides[0] > highest): highest = domino.sides[0]\n",
    "        return highest\n",
    "    def intializeTrain(self):\n",
    "        if not hasattr(self,\"train\"):\n",
    "            self.train = Train(self.id)\n",
    "        return self.train\n",
    "    def getDominoFromSides(self,s1:int,s2:int):\n",
    "        for domino in self.hand:\n",
    "            if (domino.sides == (s1,s2) or domino.sides == (s2,s1)):\n",
    "                return domino\n",
    "    def play(self, domino:Domino, placement:int, train:Train|None=None,firstDouble:bool=False):\n",
    "        selfTrain = False\n",
    "        played = False\n",
    "        if train is None: \n",
    "            train = self.train\n",
    "            selfTrain = True\n",
    "        if firstDouble: \n",
    "            self.hand.remove(domino)\n",
    "            played = True\n",
    "        elif train.add(placement, domino) != False:\n",
    "            self.hand.remove(domino)\n",
    "            if selfTrain: self.train.trainUp = False\n",
    "            played = True\n",
    "        if len(self.hand) <= 0: return None\n",
    "        else: return played\n",
    "        \n",
    "\n",
    "    def pointsInHand(self):\n",
    "        return functools.reduce(lambda acc, domino: acc + domino.calc_points(), self.hand, 0)\n",
    "    def pickup(self,boneYard:BoneYard):\n",
    "        domino = boneYard.draw()\n",
    "        if domino is not False:\n",
    "            self.hand.append(domino)\n",
    "        return domino\n",
    "    def __str__(self):\n",
    "        return f\"id:{self.id} train:{self.train.id}\"\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "class Game():\n",
    "    def __init__(self,numPlayers:int):\n",
    "        self.boneyard = BoneYard()\n",
    "        self.players = []\n",
    "        self.trains = []\n",
    "        self.done = False\n",
    "        self.numPlayers = numPlayers\n",
    "        self.unsastifiedDouble = None\n",
    "        if(numPlayers<= 4): Player.handSize = 15\n",
    "        elif(numPlayers<=6): Player.handSize = 12\n",
    "        elif(numPlayers<=8): Player.handSize = 10\n",
    "        Player.nextID = 0\n",
    "        for _ in range(numPlayers): \n",
    "            self.players.append(Player(self.boneyard))\n",
    "        doubles = [player.highestDouble() for player in self.players]\n",
    "        highestDouble = max(doubles)\n",
    "        firstPlayer = doubles.index(highestDouble)\n",
    "        firstDomino = self.players[firstPlayer].getDominoFromSides(highestDouble,highestDouble)\n",
    "        for player in self.players: \n",
    "            player.intializeTrain()\n",
    "            self.trains.append(player.train)\n",
    "        if (len(self.players)<8): self.mexican = Train(8)\n",
    "        self.centerDouble = max(doubles)\n",
    "        Train.startingSide = self.centerDouble\n",
    "        self.players[firstPlayer].play(firstDomino,0,firstDouble=True) #removing first double\n",
    "        self.startingPlayer = self.nextPlayer(firstPlayer)\n",
    "        self.prevPlayer = None\n",
    "    def getTrain(self,id:int):\n",
    "        if id == 8: return self.mexican\n",
    "        else:\n",
    "            for t in self.trains:\n",
    "                if t.id==id:\n",
    "                    return t\n",
    "            else:\n",
    "                return None\n",
    "    def getPlayer(self,id:int):\n",
    "        if id > 7: return None\n",
    "        else: \n",
    "            for p in self.players:\n",
    "                if p.id==id:\n",
    "                    return p\n",
    "            else:\n",
    "                return None\n",
    "    def nextPlayer(self, currPlayer:int):\n",
    "        next = currPlayer+1 \n",
    "        if (next>=self.numPlayers): next = 0 # looping around if its not an actual player\n",
    "        return next\n",
    "\n",
    "class BoardState():\n",
    "    def __init__(self, trains:list[Train],centerDouble:int, mexican:Train|None = None,unsastifiedDouble=None):\n",
    "        self.mexican = mexican\n",
    "        self.trains = trains\n",
    "        self.unsastifiedDouble = unsastifiedDouble\n",
    "    #train up returns only sides that are on trains with thier trains up\n",
    "    #maybe this signature should be changed to just take a list of trains? and let caller deal with filtering?\n",
    "    def getPlacements(self, trainUp: bool=False,include:list[Train]=[], exclude:list[Train]=[]):\n",
    "        trains = [*self.trains,self.mexican]\n",
    "        placements = []\n",
    "        if trainUp:\n",
    "            for train in trains:\n",
    "                if (train in include or train.trainUp) and train not in exclude:\n",
    "                    for side in train.openSides: \n",
    "                        placements.append((train.id,side))\n",
    "        else:\n",
    "            for train in trains: \n",
    "                if train not in exclude:\n",
    "                    for side in train.openSides: placements.append((train.id,side))\n",
    "        return placements\n",
    "    def getTrain(self, id):\n",
    "        for train in self.trains:\n",
    "            if train.id == id: return train\n",
    "    def availablePlays(self, player:Player,placements:list|None=None):\n",
    "        plays = []\n",
    "        places = []\n",
    "        if self.unsastifiedDouble is not None:\n",
    "            places = [self.unsastifiedDouble]\n",
    "        elif placements is not None:\n",
    "            places = placements\n",
    "        elif player.train.trainUp:\n",
    "            places = [(player.id, side) for side in player.train.openSides]\n",
    "        else: places = self.getPlacements(trainUp=True, include=[player.train])\n",
    "        for placement in places:\n",
    "            for domino in player.hand:\n",
    "                eval = domino.evalute_side(placement[1])\n",
    "                if( eval is not None): plays.append((domino.sides, placement))\n",
    "        return plays\n",
    "    def isValidPlay(self, player:Player, action:list[list]):\n",
    "        valid = False\n",
    "        plays = self.availablePlays(player)\n",
    "        for play in plays:\n",
    "            tuplist = [tuple(list) for list in action]\n",
    "            if tuple(tuplist) == play:\n",
    "                valid = True\n",
    "                print(f\"valid play: {play}\")\n",
    "        return valid\n",
    "    @staticmethod\n",
    "    def fromGame(game:Game):\n",
    "        return BoardState(game.trains,game.centerDouble, game.mexican,game.unsastifiedDouble)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cd1272-e9b0-4b30-9652-d34d4515505d",
   "metadata": {},
   "source": [
    "<h2>Test Game Objects</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11681fba-811b-4a83-a4a8-dd9fb89222ca",
   "metadata": {},
   "source": [
    "<h3>Testing intialization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7df7a61-86a3-446a-8ed7-011f44525436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id:0 train:0', 'id:1 train:1', 'id:2 train:2', 'id:3 train:3', 'id:4 train:4', 'id:5 train:5']\n",
      "['(1, 3)', '(3, 10)', '(2, 5)', '(0, 1)', '(0, 6)', '(7, 10)', '(4, 4)', '(9, 11)', '(4, 11)', '(8, 8)', '(10, 12)', '(6, 8)']\n",
      "11\n",
      "[((9, 11), (0, 11)), ((4, 11), (0, 11))]\n"
     ]
    }
   ],
   "source": [
    "game = Game(6)\n",
    "bs = BoardState.fromGame(game)\n",
    "print([str(player) for player in game.players])\n",
    "print([str(domino) for domino in game.players[0].hand])\n",
    "print(Train.startingSide)\n",
    "plays = bs.availablePlays(game.players[0])\n",
    "print(plays)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b8f168-0b05-45c2-803f-dd8ba0a25714",
   "metadata": {},
   "source": [
    "<h3>Testing random play</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "052cf609-5d31-4c88-8720-f9fda5f0b38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 0 trainUp?:False openSides: [12]\n",
      "id: 0 trainUp?:False openSides: [4]\n"
     ]
    }
   ],
   "source": [
    "plays = bs.availablePlays(game.players[0])\n",
    "if len(plays)> 0:\n",
    "    play = plays[random.randint(0, len(plays) - 1)] # play = (dominoSideTuple,placementTuple)\n",
    "    player = game.getPlayer(0)\n",
    "    domino = player.getDominoFromSides(*play[0])\n",
    "    train = bs.getTrain(play[1][0]) # play[1] is placement, = (train.id, side)\n",
    "    print(train)\n",
    "    player.play(domino,play[1][1],train)\n",
    "    print(train)\n",
    "else:\n",
    "    print(\"no possible plays\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf36d572-3d38-4015-84b5-66631a2f2b53",
   "metadata": {},
   "source": [
    "<h1>Start Making Env</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ac1632c-6ba3-4b75-8155-5c09b0ee7b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load DominoEnv.py\n",
    "from gymnasium import Env\n",
    "from gym.spaces import Dict, Discrete , MultiDiscrete, Box, Sequence\n",
    "import numpy as np\n",
    "class DominoTrainEnv(Env):\n",
    "    def __init__(self,numPlayers:int):\n",
    "        # Actions we can take, 13,13 for possible domino sides, [9,13] for possible domino placements\n",
    "        self.action_space = MultiDiscrete(np.array([[13, 13], [9, 13]]))\n",
    "        # observation space\n",
    "        obsv =  {\n",
    "        \"hand\": Sequence(MultiDiscrete(np.array([13, 13]), dtype=np.int8)),\n",
    "        \"placements\": Sequence(MultiDiscrete(np.array([9, 13]), dtype=np.int8)),\n",
    "        \"available-actions\": Sequence(MultiDiscrete(np.array([[13, 13], [9, 13]]), dtype=np.int8)),\n",
    "        \"trains\": Sequence(MultiDiscrete(np.array([9, 2]), dtype=np.int8))\n",
    "        }\n",
    "        self.observation_space = Dict(obsv)\n",
    "        #setup game\n",
    "        self.game = Game(numPlayers)\n",
    "        self.player = self.game.getPlayer(0)\n",
    "        bs = BoardState.fromGame(self.game)\n",
    "        handarray = [domino.sides for domino in self.player.hand]\n",
    "        placements = bs.getPlacements()\n",
    "        state = {\n",
    "            \"hand\": handarray,\n",
    "            \"placements\": placements,\n",
    "            \"available-actions\": bs.availablePlays(self.player),\n",
    "            \"trains\": [[train.id,train.trainUp]for train in bs.trains]\n",
    "        }\n",
    "        self.state = state\n",
    "        self.fails = 0\n",
    "        \n",
    "    def play(self,domino:Domino, placement,player:Player, bs:BoardState):\n",
    "        print(f\"attempting to play {domino} on {placement} from {player}\")\n",
    "        game = self.game\n",
    "        played = False\n",
    "        if domino is not None:\n",
    "            train = game.getTrain(placement[0])\n",
    "            if player.play(domino,placement[1],train):\n",
    "                played = True   \n",
    "                if domino.isDouble:\n",
    "                    print(\"double played\")\n",
    "                    players = game.players\n",
    "                    start_index = players.index(player)\n",
    "                    #loop through all players at \"table\" starting with person who played double\n",
    "                    for i in range(len(players)):\n",
    "                        index = (start_index + i) % len(players)\n",
    "                        loop_player = players[index] \n",
    "                        newPlacement = (placement[0],domino.sides[0])\n",
    "                        plays = bs.availablePlays(loop_player, placements=[placement])\n",
    "                        print(f\"checking if {loop_player} can play on {newPlacement}\\n, plays {plays}\")\n",
    "                        #if player can't play on double\n",
    "                        if len(plays)<=0:\n",
    "                            pickupDomino = loop_player.pickup(self.game.boneyard)\n",
    "                            #if a domino was actually picked up\n",
    "                            if pickupDomino:\n",
    "                                print(f\"{loop_player} pickedup {pickupDomino}\")\n",
    "                                plays = bs.availablePlays(loop_player, placements=[newPlacement])\n",
    "                                if len(plays)<=0: \n",
    "                                    print(\"player can't play pickup\")\n",
    "                                    loop_player.train.trainUp = True\n",
    "                                    continue\n",
    "                                #if possible to play pickup\n",
    "                                else:\n",
    "                                    print(f\"attepmting to play pickup on {newPlacement}, train {train}\")\n",
    "                                    if loop_player.play(pickupDomino,newPlacement[1],train) is None:\n",
    "                                        game.done = True\n",
    "                                    break\n",
    "                                    \n",
    "                            # no domino was pickedup, meaning boneyard is empty and end of game\n",
    "                            else:\n",
    "                                game.done = True\n",
    "                                break\n",
    "                        #if player only has one choice to play\n",
    "                        elif len(plays) == 1:\n",
    "                            play = plays[0]\n",
    "                            ranDomino = loop_player.getDominoFromSides(*play[0])\n",
    "                            print(f\"attempting to play {ranDomino} on {newPlacement}, player.train: {player.train}\")\n",
    "                            if loop_player.play(ranDomino,newPlacement[1],train) is None:\n",
    "                                game.done = True\n",
    "                            break\n",
    "                        #if player has many choices to play\n",
    "                        else:\n",
    "                            #if ai player\n",
    "                            if loop_player.id == 0:\n",
    "                                print(f\"letting ai make choice for double play\")\n",
    "                                self.game.unsastifiedDouble = (train.id,domino.sides[0])\n",
    "                                self.game.prevPlayer = player.id\n",
    "                                break\n",
    "                            #if other players, random choice\n",
    "                            else:\n",
    "                                print(player.train)\n",
    "                                play = plays[random.randint(0, len(plays) - 1)]\n",
    "                                ranDomino = loop_player.getDominoFromSides(*play[0])\n",
    "                                print(f\"attempting to play {ranDomino} on {newPlacement}, player.train: {player.train}\\n available plays: {plays}\")\n",
    "                                if loop_player.play(ranDomino,newPlacement[1],train) is None:\n",
    "                                    game.done = True\n",
    "                            break\n",
    "            else:\n",
    "                   print(\"Invalid Placement\")\n",
    "        else:\n",
    "            print(\"Invlaid Domino\")\n",
    "        return played\n",
    "    def maskAction(self,availablActions):\n",
    "        pass\n",
    "    def step(self, action):\n",
    "        start_index = self.game.startingPlayer\n",
    "        players = self.game.players\n",
    "        length = len(players)\n",
    "        stateChanged = False\n",
    "        reward = 0\n",
    "        bs= BoardState.fromGame(self.game)\n",
    "        if bs.isValidPlay(self.player,action):\n",
    "            if bs.unsastifiedDouble is not None:\n",
    "                domino = action[0]\n",
    "                domino = self.player.getDominoFromSides(*domino)\n",
    "                self.play(domino,action[1],self.player,bs)\n",
    "                reward += domino.calc_points()\n",
    "                stateChanged = True\n",
    "                start_index = self.game.nextPlayer(self.player.id)\n",
    "                length = length - 1\n",
    "                bs.unsastifiedDouble = None #probably a better way of doing this\n",
    "                self.game.unsastifiedDouble = None\n",
    "            if stateChanged or bs.unsastifiedDouble is None:    \n",
    "                for i in range(length):\n",
    "                    index = (start_index + i) % length\n",
    "                    player = players[index]\n",
    "                    posActions = bs.availablePlays(player)\n",
    "                    #if current turn is ai\n",
    "                    if player.id == 0:\n",
    "                        #if no action available\n",
    "                        if len(posActions)<=0:\n",
    "                            self.player.pickup(self.game.boneyard)\n",
    "                            posActions = bs.availablePlays(self.player)\n",
    "                            if len(posActions)>0:\n",
    "                                ranAction = posActions[0]\n",
    "                                ranDomino = self.player.getDominoFromSides(*ranAction[0])\n",
    "                                self.play(ranDomino,ranAction[1],self.player,bs)\n",
    "                                stateChanged = True\n",
    "                            # Check if action is valid\n",
    "                        else:\n",
    "                            # Apply action\n",
    "                            domino = action[0]\n",
    "                            domino = self.player.getDominoFromSides(*domino)\n",
    "                            self.play(domino,action[1],self.player,bs)\n",
    "                            reward += domino.calc_points()\n",
    "                            stateChanged = True\n",
    "                        #invalid action   \n",
    "                        \n",
    "                    else:\n",
    "                        print(f\"current turn: {player}, plays: {posActions}\")\n",
    "                        if len(posActions)<=0:\n",
    "                            player.pickup(self.game.boneyard)\n",
    "                            posActions = bs.availablePlays(player)\n",
    "                        if len(posActions)>0:\n",
    "                            ranIndex = 0\n",
    "                            if len(posActions)>1: ranIndex = random.randint(0, len(posActions)-1)\n",
    "                            ranAction = posActions[ranIndex]\n",
    "                            ranDomino = player.getDominoFromSides(*ranAction[0])\n",
    "                            self.play(ranDomino,ranAction[1],player,bs)\n",
    "                            stateChanged = True\n",
    "        else: \n",
    "            reward += -500\n",
    "            self.fails +=1\n",
    "        if stateChanged:    \n",
    "            #assigning state\n",
    "            handarray = [domino.sides for domino in self.player.hand]\n",
    "            placements = bs.getPlacements()\n",
    "            state = {\n",
    "                \"hand\": handarray,\n",
    "                \"placements\": placements,\n",
    "                \"available-actions\": bs.availablePlays(self.player),\n",
    "                \"trains\": [[train.id,train.trainUp]for train in bs.trains]\n",
    "            }\n",
    "            self.state = state\n",
    "        \n",
    "        done = self.game.done\n",
    "        #hard limit on game length since, the ai can make invalid plays which could loop forever\n",
    "        if self.fails >=10000: done = True\n",
    "        if done:\n",
    "            # add negative reward for points remaining in hand at game end\n",
    "            reward += -1*self.player.pointsInHand()  \n",
    "        \n",
    "        # Set placeholder for info\n",
    "        info = {}\n",
    "        \n",
    "        # Return step information\n",
    "        return self.state, reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        # Implement viz\n",
    "        pass\n",
    "    \n",
    "    def reset(self):\n",
    "        self.game = Game(self.game.numPlayers)\n",
    "        self.player = self.game.getPlayer(0)\n",
    "        bs = BoardState.fromGame(self.game)\n",
    "        handarray = [domino.sides for domino in self.player.hand]\n",
    "        placements = bs.getPlacements()\n",
    "        state = {\n",
    "            \"hand\": handarray,\n",
    "            \"placements\": placements,\n",
    "            \"available-actions\": bs.availablePlays(self.player),\n",
    "            \"trains\": [[train.id,train.trainUp]for train in bs.trains]\n",
    "        }\n",
    "        self.state = state\n",
    "        self.fails = 0\n",
    "        return self.state\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd71542f-3e49-4e15-8515-6ea2369d6e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = DominoTrainEnv(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c9d045a-4d17-4a76-b554-0e71a166be46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode:1 Score:-5000164\n",
      "10000\n",
      "Episode:2 Score:-5000160\n",
      "10000\n",
      "valid play: ((2, 12), (0, 12))\n",
      "current turn: id:5 train:5, plays: [((1, 12), (5, 12)), ((3, 12), (5, 12)), ((7, 12), (5, 12))]\n",
      "attempting to play (3, 12) on (5, 12) from id:5 train:5\n",
      "attempting to play (2, 12) on [ 0 12] from id:0 train:0\n",
      "current turn: id:1 train:1, plays: [((9, 12), (1, 12))]\n",
      "attempting to play (9, 12) on (1, 12) from id:1 train:1\n",
      "current turn: id:2 train:2, plays: [((8, 12), (2, 12)), ((6, 12), (2, 12))]\n",
      "attempting to play (6, 12) on (2, 12) from id:2 train:2\n",
      "current turn: id:3 train:3, plays: [((4, 12), (3, 12)), ((5, 12), (3, 12))]\n",
      "attempting to play (5, 12) on (3, 12) from id:3 train:3\n",
      "current turn: id:4 train:4, plays: []\n",
      "Episode:3 Score:-5000100\n",
      "10001\n",
      "Episode:4 Score:-5000152\n",
      "10000\n",
      "valid play: ((9, 12), (0, 12))\n",
      "current turn: id:3 train:3, plays: [((4, 12), (3, 12)), ((2, 12), (3, 12)), ((10, 12), (3, 12))]\n",
      "attempting to play (4, 12) on (3, 12) from id:3 train:3\n",
      "current turn: id:4 train:4, plays: []\n",
      "current turn: id:5 train:5, plays: [((7, 12), (5, 12))]\n",
      "attempting to play (7, 12) on (5, 12) from id:5 train:5\n",
      "attempting to play (9, 12) on [ 0 12] from id:0 train:0\n",
      "current turn: id:1 train:1, plays: [((5, 12), (1, 12))]\n",
      "attempting to play (5, 12) on (1, 12) from id:1 train:1\n",
      "current turn: id:2 train:2, plays: [((3, 12), (2, 12)), ((11, 12), (2, 12))]\n",
      "attempting to play (11, 12) on (2, 12) from id:2 train:2\n",
      "Episode:5 Score:-5000115\n",
      "10001\n",
      "valid play: ((5, 11), (0, 11))\n",
      "current turn: id:2 train:2, plays: [((9, 11), (2, 11)), ((8, 11), (2, 11))]\n",
      "attempting to play (9, 11) on (2, 11) from id:2 train:2\n",
      "current turn: id:3 train:3, plays: [((0, 11), (3, 11)), ((7, 11), (3, 11)), ((2, 11), (3, 11))]\n",
      "attempting to play (2, 11) on (3, 11) from id:3 train:3\n",
      "current turn: id:4 train:4, plays: [((3, 11), (4, 11))]\n",
      "attempting to play (3, 11) on (4, 11) from id:4 train:4\n",
      "current turn: id:5 train:5, plays: [((10, 11), (5, 11))]\n",
      "attempting to play (10, 11) on (5, 11) from id:5 train:5\n",
      "attempting to play (5, 11) on [ 0 11] from id:0 train:0\n",
      "current turn: id:1 train:1, plays: []\n",
      "Episode:6 Score:-5000119\n",
      "10001\n",
      "valid play: ((6, 12), (0, 12))\n",
      "current turn: id:5 train:5, plays: [((2, 12), (5, 12)), ((4, 12), (5, 12))]\n",
      "attempting to play (4, 12) on (5, 12) from id:5 train:5\n",
      "attempting to play (6, 12) on [ 0 12] from id:0 train:0\n",
      "current turn: id:1 train:1, plays: [((7, 12), (1, 12))]\n",
      "attempting to play (7, 12) on (1, 12) from id:1 train:1\n",
      "current turn: id:2 train:2, plays: []\n",
      "attempting to play (5, 12) on (2, 12) from id:2 train:2\n",
      "current turn: id:3 train:3, plays: [((3, 12), (3, 12))]\n",
      "attempting to play (3, 12) on (3, 12) from id:3 train:3\n",
      "current turn: id:4 train:4, plays: [((8, 12), (4, 12))]\n",
      "attempting to play (8, 12) on (4, 12) from id:4 train:4\n",
      "valid play: ((6, 6), (0, 6))\n",
      "current turn: id:5 train:5, plays: [((4, 7), (5, 4))]\n",
      "attempting to play (4, 7) on (5, 4) from id:5 train:5\n",
      "attempting to play (6, 6) on [0 6] from id:0 train:0\n",
      "double played\n",
      "checking if id:0 train:0 can play on (0, 6)\n",
      ", plays [((6, 7), array([0, 6], dtype=int64))]\n",
      "attempting to play (6, 7) on (0, 6), player.train: id: 0 trainUp?:False openSides: [6, 6]\n",
      "current turn: id:1 train:1, plays: []\n",
      "current turn: id:2 train:2, plays: [((5, 7), (2, 5)), ((2, 5), (2, 5))]\n",
      "attempting to play (5, 7) on (2, 5) from id:2 train:2\n",
      "current turn: id:3 train:3, plays: []\n",
      "current turn: id:4 train:4, plays: [((8, 10), (4, 8)), ((2, 8), (4, 8)), ((8, 9), (4, 8))]\n",
      "attempting to play (2, 8) on (4, 8) from id:4 train:4\n",
      "Episode:7 Score:-5000082\n",
      "10002\n",
      "valid play: ((5, 12), (0, 12))\n",
      "current turn: id:1 train:1, plays: [((3, 12), (1, 12)), ((9, 12), (1, 12))]\n",
      "attempting to play (9, 12) on (1, 12) from id:1 train:1\n",
      "current turn: id:2 train:2, plays: []\n",
      "current turn: id:3 train:3, plays: [((4, 12), (3, 12))]\n",
      "attempting to play (4, 12) on (3, 12) from id:3 train:3\n",
      "current turn: id:4 train:4, plays: [((8, 12), (4, 12)), ((2, 12), (4, 12)), ((0, 12), (4, 12)), ((1, 12), (4, 12))]\n",
      "attempting to play (8, 12) on (4, 12) from id:4 train:4\n",
      "current turn: id:5 train:5, plays: [((7, 12), (5, 12))]\n",
      "attempting to play (7, 12) on (5, 12) from id:5 train:5\n",
      "attempting to play (5, 12) on [ 0 12] from id:0 train:0\n",
      "valid play: ((5, 5), (0, 5))\n",
      "current turn: id:1 train:1, plays: [((9, 11), (1, 9)), ((8, 9), (1, 9)), ((6, 9), (1, 9))]\n",
      "attempting to play (9, 11) on (1, 9) from id:1 train:1\n",
      "current turn: id:2 train:2, plays: []\n",
      "current turn: id:3 train:3, plays: [((4, 9), (3, 4)), ((0, 4), (3, 4)), ((2, 4), (3, 4)), ((4, 5), (3, 4))]\n",
      "attempting to play (4, 9) on (3, 4) from id:3 train:3\n",
      "current turn: id:4 train:4, plays: [((1, 8), (4, 8)), ((0, 8), (4, 8)), ((8, 11), (4, 8))]\n",
      "attempting to play (8, 11) on (4, 8) from id:4 train:4\n",
      "current turn: id:5 train:5, plays: [((0, 7), (5, 7)), ((6, 7), (5, 7))]\n",
      "attempting to play (0, 7) on (5, 7) from id:5 train:5\n",
      "attempting to play (5, 5) on [0 5] from id:0 train:0\n",
      "double played\n",
      "checking if id:0 train:0 can play on (0, 5)\n",
      ", plays [((5, 11), array([0, 5], dtype=int64)), ((3, 5), array([0, 5], dtype=int64)), ((5, 7), array([0, 5], dtype=int64))]\n",
      "letting ai make choice for double play\n",
      "Episode:8 Score:-5000087\n",
      "10002\n",
      "valid play: ((6, 12), (0, 12))\n",
      "current turn: id:3 train:3, plays: [((3, 12), (3, 12))]\n",
      "attempting to play (3, 12) on (3, 12) from id:3 train:3\n",
      "current turn: id:4 train:4, plays: []\n",
      "current turn: id:5 train:5, plays: [((4, 12), (5, 12)), ((9, 12), (5, 12)), ((7, 12), (5, 12))]\n",
      "attempting to play (4, 12) on (5, 12) from id:5 train:5\n",
      "attempting to play (6, 12) on [ 0 12] from id:0 train:0\n",
      "current turn: id:1 train:1, plays: [((8, 12), (1, 12)), ((11, 12), (1, 12))]\n",
      "attempting to play (8, 12) on (1, 12) from id:1 train:1\n",
      "current turn: id:2 train:2, plays: [((1, 12), (2, 12))]\n",
      "attempting to play (1, 12) on (2, 12) from id:2 train:2\n",
      "Episode:9 Score:-5000108\n",
      "10001\n",
      "Episode:10 Score:-5000133\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0 \n",
    "    step = 0\n",
    "    while not done:\n",
    "        #env.render()\n",
    "        #print(step)\n",
    "        step+=1\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ddf048-2764-4971-aae3-b820d3e3a993",
   "metadata": {},
   "source": [
    "<h1>Make RL Model</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82669a39-f838-452f-a1df-0550262ff77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3 import PPO\n",
    "from gym.wrappers import FlattenObservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4a6729a-22cb-4f97-8c8e-7066f700e3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.base_class import BaseAlgorithm\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    model: BaseAlgorithm,\n",
    "    num_episodes: int = 100,\n",
    "    deterministic: bool = True,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Evaluate an RL agent for `num_episodes`.\n",
    "\n",
    "    :param model: the RL Agent\n",
    "    :param env: the gym Environment\n",
    "    :param num_episodes: number of episodes to evaluate it\n",
    "    :param deterministic: Whether to use deterministic or stochastic actions\n",
    "    :return: Mean reward for the last `num_episodes`\n",
    "    \"\"\"\n",
    "    # This function will only work for a single environment\n",
    "    vec_env = model.get_env()\n",
    "    obs = vec_env.reset()\n",
    "    all_episode_rewards = []\n",
    "    for _ in range(num_episodes):\n",
    "        episode_rewards = []\n",
    "        done = False\n",
    "        # Note: SB3 VecEnv resets automatically:\n",
    "        # https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html#vecenv-api-vs-gym-api\n",
    "        # obs = vec_env.reset()\n",
    "        while not done:\n",
    "            # _states are only useful when using LSTM policies\n",
    "            # `deterministic` is to use deterministic actions\n",
    "            action, _states = model.predict(obs, deterministic=deterministic)\n",
    "            # here, action, rewards and dones are arrays\n",
    "            # because we are using vectorized env\n",
    "            obs, reward, done, _info = vec_env.step(action)\n",
    "            episode_rewards.append(reward)\n",
    "\n",
    "        all_episode_rewards.append(sum(episode_rewards))\n",
    "\n",
    "    mean_episode_reward = np.mean(all_episode_rewards)\n",
    "    print(f\"Mean reward: {mean_episode_reward:.2f} - Num episodes: {num_episodes}\")\n",
    "\n",
    "    return mean_episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "96e1d67b-a04a-4d12-9ce8-56c9f7492fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dict('available-actions': Sequence(MultiDiscrete([[13 13]\n",
      " [ 9 13]])), 'hand': Sequence(MultiDiscrete([13 13])), 'placements': Sequence(MultiDiscrete([ 9 13])), 'trains': Sequence(MultiDiscrete([9 2])))\n",
      "Dict('available-actions': Sequence(Box(0, 1, (48,), int8)), 'hand': Sequence(Box(0, 1, (26,), int8)), 'placements': Sequence(Box(0, 1, (22,), int8)), 'trains': Sequence(Box(0, 1, (11,), int8)))\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(env\u001b[38;5;241m.\u001b[39mobservation_space)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Initialize the PPO agent\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mA2C\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMlpPolicy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Train the agent\u001b[39;00m\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\a2c\\a2c.py:87\u001b[0m, in \u001b[0;36mA2C.__init__\u001b[1;34m(self, policy, env, learning_rate, n_steps, gamma, gae_lambda, ent_coef, vf_coef, max_grad_norm, rms_prop_eps, use_rms_prop, use_sde, sde_sample_freq, normalize_advantage, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     65\u001b[0m     policy: Union[\u001b[38;5;28mstr\u001b[39m, Type[ActorCriticPolicy]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     85\u001b[0m     _init_setup_model: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     86\u001b[0m ):\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgae_lambda\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgae_lambda\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43ment_coef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ment_coef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvf_coef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvf_coef\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_grad_norm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_grad_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43msde_sample_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msde_sample_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstats_window_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats_window_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_init_setup_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupported_action_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBox\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDiscrete\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiDiscrete\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m            \u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMultiBinary\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_advantage \u001b[38;5;241m=\u001b[39m normalize_advantage\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# Update optimizer inside the policy if we want to use RMSProp\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# (original implementation) rather than Adam\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:81\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.__init__\u001b[1;34m(self, policy, env, learning_rate, n_steps, gamma, gae_lambda, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, stats_window_size, tensorboard_log, monitor_wrapper, policy_kwargs, verbose, seed, device, _init_setup_model, supported_action_spaces)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     60\u001b[0m     policy: Union[\u001b[38;5;28mstr\u001b[39m, Type[ActorCriticPolicy]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     79\u001b[0m     supported_action_spaces: Optional[Tuple[Type[spaces\u001b[38;5;241m.\u001b[39mSpace], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     80\u001b[0m ):\n\u001b[1;32m---> 81\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43msde_sample_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msde_sample_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupport_multi_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstats_window_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats_window_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupported_action_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msupported_action_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps \u001b[38;5;241m=\u001b[39m n_steps\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m=\u001b[39m gamma\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\base_class.py:169\u001b[0m, in \u001b[0;36mBaseAlgorithm.__init__\u001b[1;34m(self, policy, env, learning_rate, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, supported_action_spaces)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m env \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    168\u001b[0m     env \u001b[38;5;241m=\u001b[39m maybe_make_env(env, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose)\n\u001b[1;32m--> 169\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonitor_wrapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mobservation_space\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39maction_space\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\base_class.py:223\u001b[0m, in \u001b[0;36mBaseAlgorithm._wrap_env\u001b[1;34m(env, verbose, monitor_wrapper)\u001b[0m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrapping the env in a DummyVecEnv.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 223\u001b[0m     env \u001b[38;5;241m=\u001b[39m \u001b[43mDummyVecEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[list-item, return-value]\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;66;03m# Make sure that dict-spaces are not nested (not supported)\u001b[39;00m\n\u001b[0;32m    226\u001b[0m check_for_nested_spaces(env\u001b[38;5;241m.\u001b[39mobservation_space)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:46\u001b[0m, in \u001b[0;36mDummyVecEnv.__init__\u001b[1;34m(self, env_fns)\u001b[0m\n\u001b[0;32m     43\u001b[0m obs_space \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mobservation_space\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys, shapes, dtypes \u001b[38;5;241m=\u001b[39m obs_space_info(obs_space)\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_obs \u001b[38;5;241m=\u001b[39m OrderedDict(\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_envs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtypes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:46\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     43\u001b[0m obs_space \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mobservation_space\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys, shapes, dtypes \u001b[38;5;241m=\u001b[39m obs_space_info(obs_space)\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_obs \u001b[38;5;241m=\u001b[39m OrderedDict([(k, np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mtuple\u001b[39m(shapes[k])), dtype\u001b[38;5;241m=\u001b[39mdtypes[k])) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys])\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs,), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "env = DominoTrainEnv(6)\n",
    "print(env.observation_space)\n",
    "env = FlattenObservation(env)\n",
    "print(env.observation_space)\n",
    "# Initialize the PPO agent\n",
    "model = A2C('MlpPolicy', env, verbose=1)\n",
    "\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"A2C_DominoTrain\")\n",
    "\n",
    "# Load the saved model\n",
    "model = A2C.load(\"A2C_DominoTrain\")\n",
    "\n",
    "# Evaluate the agent\n",
    "mean_reward, _ = model.evaluate(env, n_eval_episodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125b2bda-c765-48ed-8de4-89221a6741fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
